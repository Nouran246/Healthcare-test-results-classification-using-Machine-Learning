{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-0KJXXEOYLNr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/Training_Set_Preprocessed_Final.csv')"
      ],
      "metadata": {
        "id": "TEYjyqe6YgZT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_temp = train_test_split(df, test_size=0.3, random_state=42)\n",
        "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "_sGQoZ3JYwR8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original dataframe size: {len(df)}\")\n",
        "print(f\"Training set size: {len(df_train)}\")\n",
        "print(f\"Validation set size: {len(df_val)}\")\n",
        "print(f\"Testing set size: {len(df_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTKJb4zMYz8t",
        "outputId": "cb73267e-13ca-4a09-c87f-8a0619eaefcf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataframe size: 50000\n",
            "Training set size: 35000\n",
            "Validation set size: 7500\n",
            "Testing set size: 7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridNaiveBayes(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, categorical_features, numerical_features, alpha=1.0, var_smoothing=1e-9):\n",
        "        self.categorical_features = categorical_features\n",
        "        self.numerical_features = numerical_features\n",
        "        self.alpha = alpha\n",
        "        self.var_smoothing = var_smoothing\n",
        "        self.multi_nb = MultinomialNB(alpha=self.alpha)\n",
        "        self.gauss_nb = GaussianNB(var_smoothing=self.var_smoothing)\n",
        "        self.classes_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_cat = X[self.categorical_features].values\n",
        "        X_num = X[self.numerical_features].values\n",
        "\n",
        "        self.multi_nb = MultinomialNB(alpha=self.alpha)\n",
        "        self.gauss_nb = GaussianNB(var_smoothing=self.var_smoothing)\n",
        "\n",
        "        self.multi_nb.fit(X_cat, y)\n",
        "        self.gauss_nb.fit(X_num, y)\n",
        "\n",
        "        self.classes_ = self.multi_nb.classes_\n",
        "        return self\n",
        "\n",
        "    def predict_log_proba(self, X):\n",
        "        X_cat = X[self.categorical_features].values\n",
        "        X_num = X[self.numerical_features].values\n",
        "\n",
        "        log_prob_cat = self.multi_nb.predict_log_proba(X_cat)\n",
        "        log_prob_num = self.gauss_nb.predict_log_proba(X_num)\n",
        "\n",
        "        return log_prob_cat + log_prob_num\n",
        "\n",
        "    def predict(self, X):\n",
        "        combined_log_proba = self.predict_log_proba(X)\n",
        "        return self.classes_[np.argmax(combined_log_proba, axis=1)]"
      ],
      "metadata": {
        "id": "mBn8xuVuZIoC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Define your dataset\n",
        "numerical_features = ['Age', 'Billing Amount']\n",
        "categorical_features = [col for col in df_train.columns if col not in numerical_features + ['Test Results']]\n",
        "X = df_train[categorical_features + numerical_features]\n",
        "y = df_train['Test Results']\n",
        "\n",
        "# === Define parameter grid\n",
        "param_grid = {\n",
        "    'alpha': [0.01, 0.1, 1.0],\n",
        "    'var_smoothing': [1e-11, 1e-9, 1e-7]\n",
        "}\n",
        "\n",
        "# === Wrap in GridSearchCV\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "hybrid_model = HybridNaiveBayes(categorical_features, numerical_features)\n",
        "\n",
        "grid = GridSearchCV(hybrid_model, param_grid, cv=skf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "grid.fit(X, y)\n",
        "\n",
        "# === Best model\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best CV accuracy:\", grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjksbLZaZOBK",
        "outputId": "b7d838b8-7b00-463f-c971-1fdac1826d0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "Best parameters: {'alpha': 1.0, 'var_smoothing': 1e-11}\n",
            "Best CV accuracy: 0.3326857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X)"
      ],
      "metadata": {
        "id": "smx6lg0cZulF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = df_val[categorical_features + numerical_features]\n",
        "y_val = df_val['Test Results']\n",
        "\n",
        "X_test = df_test[categorical_features + numerical_features]\n",
        "y_test = df_test['Test Results']\n",
        "\n",
        "# === Predict on validation set\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# === Predict on test set\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "print(\"Test Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw6hpz0IZnXh",
        "outputId": "589006a4-0863-4fa2-e8a4-d949e6e4fb97"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.35      0.34      2464\n",
            "           1       0.33      0.23      0.27      2509\n",
            "           2       0.33      0.42      0.37      2527\n",
            "\n",
            "    accuracy                           0.33      7500\n",
            "   macro avg       0.33      0.33      0.33      7500\n",
            "weighted avg       0.33      0.33      0.33      7500\n",
            "\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.34      0.33      2547\n",
            "           1       0.31      0.22      0.26      2440\n",
            "           2       0.35      0.44      0.39      2513\n",
            "\n",
            "    accuracy                           0.33      7500\n",
            "   macro avg       0.33      0.33      0.33      7500\n",
            "weighted avg       0.33      0.33      0.33      7500\n",
            "\n"
          ]
        }
      ]
    }
  ]
}