{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "3cp5dmxrTPQ4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1cQwdhstTSBa"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('C:/Users/pc/Documents/GitHub/Healthcare-test-results-classification-using-Machine-Learning/Preprocessed Datasets/Training_Set_Preprocessed_Final.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "23ggsPj-TaKk"
      },
      "outputs": [],
      "source": [
        "df_train, df_temp = train_test_split(df, test_size=0.3, random_state=42)\n",
        "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwW8JeFsTbVs",
        "outputId": "bb0cf76e-63da-42b7-9609-dc30cb6b9452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original dataframe size: 44167\n",
            "Training set size: 30916\n",
            "Validation set size: 6625\n",
            "Testing set size: 6626\n"
          ]
        }
      ],
      "source": [
        "print(f\"Original dataframe size: {len(df)}\")\n",
        "print(f\"Training set size: {len(df_train)}\")\n",
        "print(f\"Validation set size: {len(df_val)}\")\n",
        "print(f\"Testing set size: {len(df_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8obf1zwkTe4n"
      },
      "outputs": [],
      "source": [
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],        # number of trees\n",
        "    'max_depth': [None, 10, 20, 30],       # max depth of each tree\n",
        "    'min_samples_split': [2, 5, 10],       # min samples to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],         # min samples per leaf node\n",
        "    'bootstrap': [True, False]              # use bootstrap samples\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Create GridSearchCV object for Random Forest\n",
        "grid_search_rf = GridSearchCV(estimator=random_forest,\n",
        "                              param_grid=param_grid_rf,\n",
        "                              cv=5,\n",
        "                              scoring='accuracy',\n",
        "                              n_jobs=-1,\n",
        "                              verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtwwIhczTgiw",
        "outputId": "fefd20bd-ebca-44e6-f3bb-452c2e09704e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
            "Best parameters for Random Forest: {'bootstrap': False, 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
            "Best cross-validation accuracy for Random Forest: 0.8490424282329861\n"
          ]
        }
      ],
      "source": [
        "# Fit GridSearchCV to the training data\n",
        "grid_search_rf.fit(df_train.drop('Test Results', axis=1), df_train['Test Results'])\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)\n",
        "print(\"Best cross-validation accuracy for Random Forest:\", grid_search_rf.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "5wvEMpb4XUPs",
        "outputId": "91e01ed1-96c5-40c9-fbfb-85670f059e1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance Metrics for Random Forest on Test Set:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Precision</td>\n",
              "      <td>0.862080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sensitivity</td>\n",
              "      <td>0.861304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F1 Score</td>\n",
              "      <td>0.861516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Accuracy</td>\n",
              "      <td>0.861304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Metric     Value\n",
              "0    Precision  0.862080\n",
              "1  Sensitivity  0.861304\n",
              "2     F1 Score  0.861516\n",
              "3     Accuracy  0.861304"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Get the best Random Forest model from GridSearchCV\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_test_rf = best_rf_model.predict(df_test.drop('Test Results', axis=1))\n",
        "y_true_test_rf = df_test['Test Results']\n",
        "\n",
        "# Get the classification report as a dictionary\n",
        "report_rf = classification_report(y_true_test_rf, y_pred_test_rf, output_dict=True)\n",
        "\n",
        "# Extract the desired metrics (weighted averages)\n",
        "precision_rf = report_rf['weighted avg']['precision']\n",
        "sensitivity_rf = report_rf['weighted avg']['recall']  # Recall is sensitivity\n",
        "f1_score_rf = report_rf['weighted avg']['f1-score']\n",
        "accuracy_rf = accuracy_score(y_true_test_rf, y_pred_test_rf)\n",
        "\n",
        "# Create a dictionary to store the metrics\n",
        "metrics_data_rf = {\n",
        "    'Metric': ['Precision', 'Sensitivity', 'F1 Score', 'Accuracy'],\n",
        "    'Value': [precision_rf, sensitivity_rf, f1_score_rf, accuracy_rf]\n",
        "}\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "metrics_df_rf = pd.DataFrame(metrics_data_rf)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"Performance Metrics for Random Forest on Test Set:\")\n",
        "display(metrics_df_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S_PJOcXlKsLD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
