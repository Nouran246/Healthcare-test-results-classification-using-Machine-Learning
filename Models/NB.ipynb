{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-0KJXXEOYLNr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Training_Set_Preprocessed_Final.csv')"
      ],
      "metadata": {
        "id": "TEYjyqe6YgZT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_temp = train_test_split(df, test_size=0.3, random_state=42)\n",
        "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "_sGQoZ3JYwR8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original dataframe size: {len(df)}\")\n",
        "print(f\"Training set size: {len(df_train)}\")\n",
        "print(f\"Validation set size: {len(df_val)}\")\n",
        "print(f\"Testing set size: {len(df_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTKJb4zMYz8t",
        "outputId": "a74fd5a5-6db2-4996-e03b-9dadd480f618"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataframe size: 44167\n",
            "Training set size: 30916\n",
            "Validation set size: 6625\n",
            "Testing set size: 6626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridNaiveBayes(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, categorical_features, numerical_features, alpha=1.0, var_smoothing=1e-9):\n",
        "        self.categorical_features = categorical_features\n",
        "        self.numerical_features = numerical_features\n",
        "        self.alpha = alpha\n",
        "        self.var_smoothing = var_smoothing\n",
        "        self.multi_nb = MultinomialNB(alpha=self.alpha)\n",
        "        self.gauss_nb = GaussianNB(var_smoothing=self.var_smoothing)\n",
        "        self.classes_ = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_cat = X[self.categorical_features].values\n",
        "        X_num = X[self.numerical_features].values\n",
        "\n",
        "        self.multi_nb = MultinomialNB(alpha=self.alpha)\n",
        "        self.gauss_nb = GaussianNB(var_smoothing=self.var_smoothing)\n",
        "\n",
        "        self.multi_nb.fit(X_cat, y)\n",
        "        self.gauss_nb.fit(X_num, y)\n",
        "\n",
        "        self.classes_ = self.multi_nb.classes_\n",
        "        return self\n",
        "\n",
        "    def predict_log_proba(self, X):\n",
        "        X_cat = X[self.categorical_features].values\n",
        "        X_num = X[self.numerical_features].values\n",
        "\n",
        "        log_prob_cat = self.multi_nb.predict_log_proba(X_cat)\n",
        "        log_prob_num = self.gauss_nb.predict_log_proba(X_num)\n",
        "\n",
        "        return log_prob_cat + log_prob_num\n",
        "\n",
        "    def predict(self, X):\n",
        "        combined_log_proba = self.predict_log_proba(X)\n",
        "        return self.classes_[np.argmax(combined_log_proba, axis=1)]"
      ],
      "metadata": {
        "id": "mBn8xuVuZIoC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Define your dataset\n",
        "numerical_features = ['Age', 'Billing Amount']\n",
        "categorical_features = [col for col in df_train.columns if col not in numerical_features + ['Test Results']]\n",
        "X = df_train[categorical_features + numerical_features]\n",
        "y = df_train['Test Results']\n",
        "\n",
        "# === Define parameter grid\n",
        "param_grid = {\n",
        "    'alpha': [0.01, 0.1, 1.0],\n",
        "    'var_smoothing': [1e-11, 1e-9, 1e-7]\n",
        "}\n",
        "\n",
        "# === Wrap in GridSearchCV\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "hybrid_model = HybridNaiveBayes(categorical_features, numerical_features)\n",
        "\n",
        "grid = GridSearchCV(hybrid_model, param_grid, cv=skf, scoring='accuracy', n_jobs=-1, verbose=2)\n",
        "grid.fit(X, y)\n",
        "\n",
        "# === Best model\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best CV accuracy:\", grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjksbLZaZOBK",
        "outputId": "ef201658-5b14-4bfe-e879-dc2aa29a158d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "Best parameters: {'alpha': 0.01, 'var_smoothing': 1e-11}\n",
            "Best CV accuracy: 0.7758764433380432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_\n",
        "y_pred = best_model.predict(X)"
      ],
      "metadata": {
        "id": "smx6lg0cZulF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = df_val[categorical_features + numerical_features]\n",
        "y_val = df_val['Test Results']\n",
        "\n",
        "X_test = df_test[categorical_features + numerical_features]\n",
        "y_test = df_test['Test Results']\n",
        "\n",
        "# === Predict on validation set\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred))\n",
        "\n",
        "# === Predict on test set\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "print(\"Test Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw6hpz0IZnXh",
        "outputId": "0eec2582-f944-4073-a8f9-6312e14acd09"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.79      0.78      2238\n",
            "           1       0.75      0.73      0.74      2221\n",
            "           2       0.82      0.82      0.82      2166\n",
            "\n",
            "    accuracy                           0.78      6625\n",
            "   macro avg       0.78      0.78      0.78      6625\n",
            "weighted avg       0.78      0.78      0.78      6625\n",
            "\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.79      0.78      2250\n",
            "           1       0.75      0.74      0.75      2233\n",
            "           2       0.82      0.82      0.82      2143\n",
            "\n",
            "    accuracy                           0.78      6626\n",
            "   macro avg       0.78      0.78      0.78      6626\n",
            "weighted avg       0.78      0.78      0.78      6626\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MCca65G6MRfx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}